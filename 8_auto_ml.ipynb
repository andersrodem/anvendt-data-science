{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall -y numpy scipy autogluon autogluon.timeseries\n",
    "!pip install numpy==1.23.5 scipy==1.9.3\n",
    "!pip install autogluon.timeseries\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training... Time limit = 9000s\n",
      "AutoGluon will save models to 'autogluon_checkpoints'\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.0.0: Mon Aug 12 20:51:54 PDT 2024; root:xnu-11215.1.10~2/RELEASE_ARM64_T6000\n",
      "CPU Count:          10\n",
      "GPU Count:          0\n",
      "Memory Avail:       3.25 GB / 16.00 GB (20.3%)\n",
      "Disk Space Avail:   182.29 GB / 926.35 GB (19.7%)\n",
      "===================================================\n",
      "Setting presets to: high_quality\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': RMSE,\n",
      " 'excluded_model_types': ['RecursiveTabular', 'DirectTabular'],\n",
      " 'freq': 'D',\n",
      " 'hyperparameters': 'default',\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 1,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'target',\n",
      " 'time_limit': 9000,\n",
      " 'verbosity': 2}\n",
      "\n",
      "Provided train_data has 766 rows, 1 time series. Median time series length is 766 (min=766, max=766). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'target'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['volume_demand', 'volume_production', 'price_lag_1d', 'price_lag_7d', 'price_lag_30d', 'month_sin', ...]\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'RMSE'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2024-10-21 11:56:34\n",
      "Excluded model types: ['RecursiveTabular', 'DirectTabular']\n",
      "\tFound 'RecursiveTabular' model in `hyperparameters`, but 'RecursiveTabular' is present in `excluded_model_types` and will be removed.\n",
      "\tFound 'DirectTabular' model in `hyperparameters`, but 'DirectTabular' is present in `excluded_model_types` and will be removed.\n",
      "Models that will be trained: ['SeasonalNaive', 'CrostonSBA', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'AutoARIMA', 'Chronos[base]', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST']\n",
      "Training timeseries model SeasonalNaive. Training for up to 840.0s of the 9000.0s of remaining time.\n",
      "\t-6.1733       = Validation score (-RMSE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t1.82    s     = Validation (prediction) runtime\n",
      "Training timeseries model CrostonSBA. Training for up to 933.1s of the 8998.2s of remaining time.\n",
      "\t-13.8595      = Validation score (-RMSE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t4.04    s     = Validation (prediction) runtime\n",
      "Training timeseries model NPTS. Training for up to 1049.3s of the 8994.1s of remaining time.\n",
      "\t-23.7301      = Validation score (-RMSE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model DynamicOptimizedTheta. Training for up to 1199.2s of the 8994.1s of remaining time.\n",
      "\t-8.3641       = Validation score (-RMSE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t9.93    s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoETS. Training for up to 1397.4s of the 8984.1s of remaining time.\n",
      "\t-9.3954       = Validation score (-RMSE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t10.55   s     = Validation (prediction) runtime\n",
      "Training timeseries model AutoARIMA. Training for up to 1674.7s of the 8973.6s of remaining time.\n",
      "\t-11.2917      = Validation score (-RMSE)\n",
      "\t0.01    s     = Training runtime\n",
      "\t5.71    s     = Validation (prediction) runtime\n",
      "Training timeseries model Chronos[base]. Training for up to 2092.0s of the 8967.8s of remaining time.\n",
      "\tWarning: Exception caused Chronos[base] to fail during training... Skipping this model.\n",
      "\tChronos[base]/W0 requires a GPU to run, but no GPU was detected. Please make sure that you are using a computer with a CUDA-compatible GPU and `import torch; torch.cuda.is_available()` returns `True`.\n",
      "Training timeseries model TemporalFusionTransformer. Training for up to 2789.3s of the 8967.8s of remaining time.\n",
      "\t-5.1546       = Validation score (-RMSE)\n",
      "\t101.26  s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Training timeseries model DeepAR. Training for up to 4133.3s of the 8866.5s of remaining time.\n",
      "\t-7.8799       = Validation score (-RMSE)\n",
      "\t19.74   s     = Training runtime\n",
      "\t0.01    s     = Validation (prediction) runtime\n",
      "Training timeseries model PatchTST. Training for up to 8246.8s of the 8846.8s of remaining time.\n",
      "\t-11.0127      = Validation score (-RMSE)\n",
      "\t19.47   s     = Training runtime\n",
      "\t0.01    s     = Validation (prediction) runtime\n",
      "Fitting simple weighted ensemble.\n",
      "\tEnsemble weights: {'TemporalFusionTransformer': 1.0}\n",
      "\t-5.1546       = Validation score (-RMSE)\n",
      "\t0.27    s     = Training runtime\n",
      "\t0.02    s     = Validation (prediction) runtime\n",
      "Training complete. Models trained: ['SeasonalNaive', 'CrostonSBA', 'NPTS', 'DynamicOptimizedTheta', 'AutoETS', 'AutoARIMA', 'TemporalFusionTransformer', 'DeepAR', 'PatchTST', 'WeightedEnsemble']\n",
      "Total runtime: 172.97 s\n",
      "Best model: TemporalFusionTransformer\n",
      "Best model score: -5.1546\n",
      "Model not specified in predict, will default to the model with the best validation score: TemporalFusionTransformer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  score_val  pred_time_val  fit_time_marginal  \\\n",
      "0           WeightedEnsemble  -5.154573       0.016153           0.273677   \n",
      "1  TemporalFusionTransformer  -5.154573       0.016153         101.260629   \n",
      "2              SeasonalNaive  -6.173333       1.815764           0.006769   \n",
      "3                     DeepAR  -7.879876       0.007127          19.736750   \n",
      "4      DynamicOptimizedTheta  -8.364108       9.926698           0.006751   \n",
      "5                    AutoETS  -9.395426      10.546663           0.010367   \n",
      "6                   PatchTST -11.012685       0.005308          19.474832   \n",
      "7                  AutoARIMA -11.291668       5.712947           0.010273   \n",
      "8                 CrostonSBA -13.859536       4.039534           0.006207   \n",
      "9                       NPTS -23.730088       0.016415           0.005893   \n",
      "\n",
      "   fit_order  \n",
      "0         10  \n",
      "1          7  \n",
      "2          1  \n",
      "3          8  \n",
      "4          4  \n",
      "5          5  \n",
      "6          9  \n",
      "7          6  \n",
      "8          2  \n",
      "9          3  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesPredictor, TimeSeriesDataFrame\n",
    "import torch\n",
    "\n",
    "# Load your preprocessed dataset\n",
    "file_path = 'automl_dataset.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure timestamp column is datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Set all rows to the same item_id (1) to create a single time series\n",
    "df['item_id'] = 1\n",
    "\n",
    "# Convert to TimeSeriesDataFrame\n",
    "df_tsd = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column='item_id',\n",
    "    timestamp_column='timestamp'\n",
    ")\n",
    "\n",
    "# Split into training and testing data\n",
    "train_size = int(len(df_tsd) * 0.8)\n",
    "split_timestamp = df_tsd.index.get_level_values(1)[train_size]\n",
    "\n",
    "train_data = df_tsd[df_tsd.index.get_level_values(1) < split_timestamp]\n",
    "test_data = df_tsd[df_tsd.index.get_level_values(1) >= split_timestamp]\n",
    "\n",
    "# Setup and train the TimeSeriesPredictor with reduced complexity\n",
    "predictor = TimeSeriesPredictor(\n",
    "    path='autogluon_checkpoints',\n",
    "    prediction_length=1,\n",
    "    \n",
    "    eval_metric='RMSE',\n",
    "    freq='D',\n",
    ")\n",
    "\n",
    "# Fit the model with reduced time limit and simpler preset\n",
    "predictor.fit(\n",
    "    train_data=train_data, \n",
    "    presets='high_quality',\n",
    "    time_limit=9000, # 2,5 hours\n",
    "    excluded_model_types=['RecursiveTabular', 'DirectTabular']\n",
    ")\n",
    "\n",
    "# Generate predictions on test data\n",
    "predictions = predictor.predict(test_data)\n",
    "\n",
    "# Save predictions\n",
    "predictions.to_csv('autogluon_predictions.csv')\n",
    "\n",
    "# Leaderboard of models\n",
    "leaderboard = predictor.leaderboard()\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
