{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id datetime_utc  volume_demand  volume_production  spot_price  \\\n",
      "0   1   2016-01-30       0.842783          -0.373537   15.345417   \n",
      "1   2   2016-01-31       0.829238          -0.051549   16.520833   \n",
      "2   3   2016-02-01       1.381032           0.839492   18.585417   \n",
      "3   4   2016-02-02       1.196450           0.382193   16.956250   \n",
      "4   5   2016-02-03       1.296145           0.846770   17.781250   \n",
      "\n",
      "   price_lag_1d  price_lag_7d  price_lag_30d  price_rolling_mean_7d  \\\n",
      "0     -1.644997     -0.783081      -1.663573              -1.427364   \n",
      "1     -1.737056     -0.969281      -1.635576              -1.520384   \n",
      "2     -1.606686     -0.759683      -1.785496              -1.610033   \n",
      "3     -1.377694     -1.430905      -1.705117              -1.628853   \n",
      "4     -1.558392     -1.589384      -1.392131              -1.611132   \n",
      "\n",
      "   price_rolling_std_7d  ...  month_8  month_9  month_10  month_11  month_12  \\\n",
      "0              1.066517  ...        0        0         0         0         0   \n",
      "1              0.789862  ...        0        0         0         0         0   \n",
      "2             -0.511740  ...        0        0         0         0         0   \n",
      "3             -0.605674  ...        0        0         0         0         0   \n",
      "4             -0.550950  ...        0        0         0         0         0   \n",
      "\n",
      "   year_2017  year_2018  season_Spring  season_Summer  season_Winter  \n",
      "0          0          0              0              0              1  \n",
      "1          0          0              0              0              1  \n",
      "2          0          0              0              0              1  \n",
      "3          0          0              0              0              1  \n",
      "4          0          0              0              0              1  \n",
      "\n",
      "[5 rows x 66 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Data columns (total 66 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   id                           958 non-null    int64         \n",
      " 1   datetime_utc                 958 non-null    datetime64[ns]\n",
      " 2   volume_demand                958 non-null    float64       \n",
      " 3   volume_production            958 non-null    float64       \n",
      " 4   spot_price                   958 non-null    float64       \n",
      " 5   price_lag_1d                 958 non-null    float64       \n",
      " 6   price_lag_7d                 958 non-null    float64       \n",
      " 7   price_lag_30d                958 non-null    float64       \n",
      " 8   price_rolling_mean_7d        958 non-null    float64       \n",
      " 9   price_rolling_std_7d         958 non-null    float64       \n",
      " 10  price_rolling_mean_30d       958 non-null    float64       \n",
      " 11  price_rolling_std_30d        958 non-null    float64       \n",
      " 12  demand_production_ratio      958 non-null    float64       \n",
      " 13  demand_lag_1d                958 non-null    float64       \n",
      " 14  production_lag_1d            958 non-null    float64       \n",
      " 15  demand_rolling_mean_7d       958 non-null    float64       \n",
      " 16  demand_rolling_std_7d        958 non-null    float64       \n",
      " 17  demand_rolling_mean_30d      958 non-null    float64       \n",
      " 18  demand_rolling_std_30d       958 non-null    float64       \n",
      " 19  production_rolling_mean_7d   958 non-null    float64       \n",
      " 20  production_rolling_std_7d    958 non-null    float64       \n",
      " 21  production_rolling_mean_30d  958 non-null    float64       \n",
      " 22  production_rolling_std_30d   958 non-null    float64       \n",
      " 23  price_change_1d              958 non-null    float64       \n",
      " 24  month_sin                    958 non-null    float64       \n",
      " 25  month_cos                    958 non-null    float64       \n",
      " 26  price_ewm_alpha_0.5          958 non-null    float64       \n",
      " 27  demand_ewm_alpha_0.5         958 non-null    float64       \n",
      " 28  production_ewm_alpha_0.5     958 non-null    float64       \n",
      " 29  price_anomaly                958 non-null    int64         \n",
      " 30  price_boxcox                 958 non-null    float64       \n",
      " 31  coal_price                   958 non-null    float64       \n",
      " 32  crude_oil_price              958 non-null    float64       \n",
      " 33  natural_gas_price            958 non-null    float64       \n",
      " 34  Fill_Level                   958 non-null    float64       \n",
      " 35  Precipitation                958 non-null    float64       \n",
      " 36  Max_Temp                     958 non-null    float64       \n",
      " 37  Avg_Temp                     958 non-null    float64       \n",
      " 38  Min_Temp                     958 non-null    float64       \n",
      " 39  Max_Wind                     958 non-null    float64       \n",
      " 40  Max_Gust                     958 non-null    float64       \n",
      " 41  Avg_Wind                     958 non-null    float64       \n",
      " 42  Snow_Depth                   958 non-null    float64       \n",
      " 43  day_of_week_1                958 non-null    int64         \n",
      " 44  day_of_week_2                958 non-null    int64         \n",
      " 45  day_of_week_3                958 non-null    int64         \n",
      " 46  day_of_week_4                958 non-null    int64         \n",
      " 47  day_of_week_5                958 non-null    int64         \n",
      " 48  day_of_week_6                958 non-null    int64         \n",
      " 49  is_weekend_1                 958 non-null    int64         \n",
      " 50  month_2                      958 non-null    int64         \n",
      " 51  month_3                      958 non-null    int64         \n",
      " 52  month_4                      958 non-null    int64         \n",
      " 53  month_5                      958 non-null    int64         \n",
      " 54  month_6                      958 non-null    int64         \n",
      " 55  month_7                      958 non-null    int64         \n",
      " 56  month_8                      958 non-null    int64         \n",
      " 57  month_9                      958 non-null    int64         \n",
      " 58  month_10                     958 non-null    int64         \n",
      " 59  month_11                     958 non-null    int64         \n",
      " 60  month_12                     958 non-null    int64         \n",
      " 61  year_2017                    958 non-null    int64         \n",
      " 62  year_2018                    958 non-null    int64         \n",
      " 63  season_Spring                958 non-null    int64         \n",
      " 64  season_Summer                958 non-null    int64         \n",
      " 65  season_Winter                958 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(40), int64(25)\n",
      "memory usage: 494.1 KB\n",
      "None\n",
      "Preprocessed dataset saved as 'preprocessed_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('prediction_dataset.csv')\n",
    "\n",
    "# Create an ID column\n",
    "data['id'] = range(1, len(data) + 1)\n",
    "\n",
    "# Move 'id' column to the first position\n",
    "cols = ['id'] + [col for col in data.columns if col != 'id']\n",
    "data = data[cols]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['day_of_week', 'is_weekend', 'month', 'year', 'season']\n",
    "data = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Ensure categorical columns are 0 and 1, not True and False\n",
    "for col in data.select_dtypes(include=['bool']).columns:\n",
    "    data[col] = data[col].astype(int)\n",
    "\n",
    "# Convert datetime_utc to datetime64\n",
    "data['datetime_utc'] = pd.to_datetime(data['datetime_utc'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "# Select numerical columns to standardize (excluding target 'spot_price' and 'id')\n",
    "numerical_columns = [\n",
    "    'volume_demand', 'volume_production', 'price_lag_1d', 'price_lag_7d', 'price_lag_30d',\n",
    "    'price_rolling_mean_7d', 'price_rolling_std_7d', 'price_rolling_mean_30d', 'price_rolling_std_30d',\n",
    "    'natural_gas_price', 'Fill_Level', 'Precipitation', 'Max_Temp', 'Avg_Temp', 'Min_Temp',\n",
    "    'Max_Wind', 'Max_Gust', 'Avg_Wind', 'Snow_Depth'\n",
    "]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standardization only to the numerical features\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Handle missing values if any\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "data[numerical_columns] = imputer.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Print the first few rows and data info to verify the changes\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Save the preprocessed dataset with the spot price as a CSV\n",
    "data.to_csv('preprocessed_dataset.csv', index=False)\n",
    "print(\"Preprocessed dataset saved as 'preprocessed_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   item_id  timestamp     target  volume_demand  volume_production  \\\n",
      "0        1 2016-01-30  15.345417       0.842783          -0.373537   \n",
      "1        2 2016-01-31  16.520833       0.829238          -0.051549   \n",
      "2        3 2016-02-01  18.585417       1.381032           0.839492   \n",
      "3        4 2016-02-02  16.956250       1.196450           0.382193   \n",
      "4        5 2016-02-03  17.781250       1.296145           0.846770   \n",
      "\n",
      "   price_lag_1d  price_lag_7d  price_lag_30d  month_sin  month_cos  ...  \\\n",
      "0     -1.644997     -0.783081      -1.663573        0.0   1.000000  ...   \n",
      "1     -1.737056     -0.969281      -1.635576        0.0   1.000000  ...   \n",
      "2     -1.606686     -0.759683      -1.785496        0.5   0.866025  ...   \n",
      "3     -1.377694     -1.430905      -1.705117        0.5   0.866025  ...   \n",
      "4     -1.558392     -1.589384      -1.392131        0.5   0.866025  ...   \n",
      "\n",
      "   month_8  month_9  month_10  month_11  month_12  year_2017  year_2018  \\\n",
      "0        0        0         0         0         0          0          0   \n",
      "1        0        0         0         0         0          0          0   \n",
      "2        0        0         0         0         0          0          0   \n",
      "3        0        0         0         0         0          0          0   \n",
      "4        0        0         0         0         0          0          0   \n",
      "\n",
      "   season_Spring  season_Summer  season_Winter  \n",
      "0              0              0              1  \n",
      "1              0              0              1  \n",
      "2              0              0              1  \n",
      "3              0              0              1  \n",
      "4              0              0              1  \n",
      "\n",
      "[5 rows x 35 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 958 entries, 0 to 957\n",
      "Data columns (total 35 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   item_id            958 non-null    int64         \n",
      " 1   timestamp          958 non-null    datetime64[ns]\n",
      " 2   target             958 non-null    float64       \n",
      " 3   volume_demand      958 non-null    float64       \n",
      " 4   volume_production  958 non-null    float64       \n",
      " 5   price_lag_1d       958 non-null    float64       \n",
      " 6   price_lag_7d       958 non-null    float64       \n",
      " 7   price_lag_30d      958 non-null    float64       \n",
      " 8   month_sin          958 non-null    float64       \n",
      " 9   month_cos          958 non-null    float64       \n",
      " 10  Fill_Level         958 non-null    float64       \n",
      " 11  Avg_Temp           958 non-null    float64       \n",
      " 12  day_of_week_1      958 non-null    int64         \n",
      " 13  day_of_week_2      958 non-null    int64         \n",
      " 14  day_of_week_3      958 non-null    int64         \n",
      " 15  day_of_week_4      958 non-null    int64         \n",
      " 16  day_of_week_5      958 non-null    int64         \n",
      " 17  day_of_week_6      958 non-null    int64         \n",
      " 18  is_weekend_1       958 non-null    int64         \n",
      " 19  month_2            958 non-null    int64         \n",
      " 20  month_3            958 non-null    int64         \n",
      " 21  month_4            958 non-null    int64         \n",
      " 22  month_5            958 non-null    int64         \n",
      " 23  month_6            958 non-null    int64         \n",
      " 24  month_7            958 non-null    int64         \n",
      " 25  month_8            958 non-null    int64         \n",
      " 26  month_9            958 non-null    int64         \n",
      " 27  month_10           958 non-null    int64         \n",
      " 28  month_11           958 non-null    int64         \n",
      " 29  month_12           958 non-null    int64         \n",
      " 30  year_2017          958 non-null    int64         \n",
      " 31  year_2018          958 non-null    int64         \n",
      " 32  season_Spring      958 non-null    int64         \n",
      " 33  season_Summer      958 non-null    int64         \n",
      " 34  season_Winter      958 non-null    int64         \n",
      "dtypes: datetime64[ns](1), float64(10), int64(24)\n",
      "memory usage: 262.1 KB\n",
      "None\n",
      "Preprocessed dataset saved as 'automl_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv(\"prediction_dataset.csv\")\n",
    "\n",
    "# Create an ID column\n",
    "data[\"item_id\"] = range(1, len(data) + 1)\n",
    "\n",
    "# Rename columns to match AutoGluon TimeSeriesDataFrame format\n",
    "data = data.rename(columns={\"datetime_utc\": \"timestamp\", \"spot_price\": \"target\"})\n",
    "\n",
    "# Move 'item_id' and 'timestamp' columns to the first positions\n",
    "cols = [\"item_id\", \"timestamp\"] + [\n",
    "    col for col in data.columns if col not in [\"item_id\", \"timestamp\"]\n",
    "]\n",
    "data = data[cols]\n",
    "\n",
    "# Convert timestamp to datetime\n",
    "data[\"timestamp\"] = pd.to_datetime(data[\"timestamp\"], utc=True).dt.tz_localize(None)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_cols = ['day_of_week', 'is_weekend', 'month', 'year', 'season']\n",
    "\n",
    "# Check which categorical columns are actually present in the data\n",
    "available_categorical_cols = [col for col in categorical_cols if col in data.columns]\n",
    "\n",
    "# One-hot encode available categorical features\n",
    "if available_categorical_cols:\n",
    "    data = pd.get_dummies(data, columns=available_categorical_cols, drop_first=True)\n",
    "\n",
    "# Ensure categorical columns are 0 and 1, not True and False\n",
    "for col in data.select_dtypes(include=[\"bool\"]).columns:\n",
    "    data[col] = data[col].astype(int)\n",
    "\n",
    "# Select numerical columns to standardize (excluding target 'target' and 'item_id')\n",
    "# numerical_columns = [\n",
    "#     'volume_demand', 'volume_production', 'price_lag_1d', 'price_lag_7d', 'price_lag_30d',\n",
    "#     'price_rolling_mean_7d', 'price_rolling_std_7d', 'price_rolling_mean_30d', 'price_rolling_std_30d',\n",
    "#     'natural_gas_price', 'Fill_Level', 'Precipitation', 'Max_Temp', 'Avg_Temp', 'Min_Temp',\n",
    "#     'Max_Wind', 'Max_Gust', 'Avg_Wind', 'Snow_Depth'\n",
    "# ]\n",
    "\n",
    "# Keep only the columns we want to standardize\n",
    "numerical_columns = [\n",
    "    \"volume_demand\",\n",
    "    \"volume_production\",\n",
    "    \"price_lag_1d\",\n",
    "    \"price_lag_7d\",\n",
    "    \"price_lag_30d\",\n",
    "    \"Fill_Level\",\n",
    "    \"Avg_Temp\",\n",
    "]\n",
    "\n",
    "# Update selected_columns to use only available columns\n",
    "selected_columns = ['item_id', 'timestamp', 'target'] + [col for col in data.columns if col in numerical_columns or col.startswith(tuple(available_categorical_cols))]\n",
    "data = data[selected_columns]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply standardization only to the numerical features\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Handle missing values if any\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "data[numerical_columns] = imputer.fit_transform(data[numerical_columns])\n",
    "\n",
    "# Print the first few rows and data info to verify the changes\n",
    "print(data.head())\n",
    "print(data.info())\n",
    "\n",
    "# Save the preprocessed dataset as a CSV\n",
    "data.to_csv(\"automl_dataset.csv\", index=False)\n",
    "print(\"Preprocessed dataset saved as 'automl_dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
